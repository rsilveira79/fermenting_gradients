{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas==0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "# Torch, Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "print(torch.__version__)\n",
    "\n",
    "## Embeddings\n",
    "import allennlp\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "## NLP libs\n",
    "from nltk import download\n",
    "import gensim\n",
    "\n",
    "stopwords = {\"ourselves\", \"hers\", \"between\", \"yourself\", \"but\", \"again\", \"there\", \"about\", \"once\", \"during\", \"out\", \"very\", \"having\", \"with\", \"they\", \"own\", \"an\", \"be\", \"some\", \"for\", \"do\", \"its\", \"yours\", \"such\", \"into\", \"of\", \"most\", \"itself\", \"other\", \"off\", \"is\", \"s\", \"am\", \"or\", \"who\", \"as\", \"from\", \"him\", \"each\", \"the\", \"themselves\", \"until\", \"below\", \"are\", \"we\", \"these\", \"your\", \"his\", \"through\", \"don\", \"nor\", \"me\", \"were\", \"her\", \"more\", \"himself\", \"this\", \"down\", \"should\", \"our\", \"their\", \"while\", \"above\", \"both\", \"up\", \"to\", \"ours\", \"had\", \"she\", \"all\", \"no\", \"when\", \"at\", \"any\", \"before\", \"them\", \"same\", \"and\", \"been\", \"have\", \"in\", \"will\", \"on\", \"does\", \"yourselves\", \"then\", \"that\", \"because\", \"what\", \"over\", \"why\", \"so\", \"can\", \"did\", \"not\", \"now\", \"under\", \"he\", \"you\", \"herself\", \"has\", \"just\", \"where\", \"too\", \"only\", \"myself\", \"which\", \"those\", \"i\", \"after\", \"few\", \"whom\", \"t\", \"being\", \"if\", \"theirs\", \"my\", \"against\", \"a\", \"by\", \"doing\", \"it\", \"how\", \"further\", \"was\", \"here\", \"than\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m2017-06-custom-intent-engines\u001b[m\u001b[m\r\n",
      "README.md\r\n",
      "Untitled.ipynb\r\n",
      "intent_classifier_uncertainty_mc_dropout.ipynb\r\n",
      "model__uncertainty.pth\r\n",
      "snips_dataset.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../personal/intents_uncertainty/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../../../personal/intents_uncertainty/2017-06-custom-intent-engines/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.DataFrame(columns = ['phrase', 'intent'])\n",
    "# for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "#                'SearchScreeningEvent']:\n",
    "#     with open(path_dataset + intent + \"/train_\" + intent + \".json\",\n",
    "#               encoding='cp1251') as data_file:\n",
    "#         data = json.load(data_file)\n",
    "#     print(\"Intent: {}, Length: {}\".format(intent,len(data[intent])))\n",
    "#     texts = []\n",
    "#     for i in range(len(data[intent])):\n",
    "#         text = ''\n",
    "#         for j in range(len(data[intent][i]['data'])):\n",
    "#             text += data[intent][i]['data'][j]['text']\n",
    "#         dataset = dataset.append({'phrase': text, 'intent': intent}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>modify her military information</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>modify worker military status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>change employee veteran status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>change his military status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>update Brian's veteran status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               phrase                      intent\n",
       "2671  modify her military information  workerVeteranStatus.update\n",
       "2672    modify worker military status  workerVeteranStatus.update\n",
       "2673   change employee veteran status  workerVeteranStatus.update\n",
       "2674       change his military status  workerVeteranStatus.update\n",
       "2675    update Brian's veteran status  workerVeteranStatus.update"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_pickle('intents_phrases_183.pkl')\n",
    "dataset = dataset.rename(columns={\"usersays\":\"phrase\"})\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Cleaning input\n",
    "    text = text.replace(\"'s\",\"\")\n",
    "    text = text.replace(\"â€™s\",\"\")\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"-\",\"\")\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Removing all the stopwords\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stopwords]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>modify her military information</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "      <td>modify military information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>modify worker military status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "      <td>modify worker military status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>change employee veteran status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "      <td>change employee veteran status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>change his military status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "      <td>change military status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>update Brian's veteran status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "      <td>update brian veteran status</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               phrase                      intent  \\\n",
       "2671  modify her military information  workerVeteranStatus.update   \n",
       "2672    modify worker military status  workerVeteranStatus.update   \n",
       "2673   change employee veteran status  workerVeteranStatus.update   \n",
       "2674       change his military status  workerVeteranStatus.update   \n",
       "2675    update Brian's veteran status  workerVeteranStatus.update   \n",
       "\n",
       "                        preproc_text  \n",
       "2671     modify military information  \n",
       "2672   modify worker military status  \n",
       "2673  change employee veteran status  \n",
       "2674          change military status  \n",
       "2675     update brian veteran status  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['preproc_text'] = dataset['phrase'].apply(lambda x: transformText(x, do_stop=True))\n",
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dicionario: 792\n"
     ]
    }
   ],
   "source": [
    "## Build word vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in dataset.preproc_text:\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(\"Tamanho do dicionario: {}\".format(len(word_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Labels: 183\n"
     ]
    }
   ],
   "source": [
    "## Build label vocabulary\n",
    "label_to_ix = {}\n",
    "for label in dataset.intent:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)\n",
    "print(\"# Labels: {}\".format(len(label_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe, w2v_weights_path):\n",
    "        self.len = len(dataframe)\n",
    "        self.label_to_ix = {}\n",
    "        self.data = dataframe\n",
    "        self.w2v = KeyedVectors.load_word2vec_format(w2v_weights_path, binary = True)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phrase = self.data.preproc_text[index]\n",
    "        X, _  = self.get_avg_sentence_vector(phrase)\n",
    "        y = label_to_ix[self.data.intent[index]]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def get_avg_sentence_vector(self, sentence):\n",
    "        featureVec = np.zeros((self.w2v.vector_size), dtype=\"float32\")\n",
    "        nwords = 0\n",
    "        not_found_words = []\n",
    "        for word in sentence.split():\n",
    "            if word in self.w2v.index2word:\n",
    "                nwords = nwords+1\n",
    "                featureVec = np.add(featureVec, self.w2v.get_vector(word))\n",
    "            else:\n",
    "                not_found_words.append(word)\n",
    "        if nwords>0:\n",
    "            featureVec = np.divide(featureVec, nwords)\n",
    "        return featureVec, not_found_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_weights_path = '../../../vectors/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=dataset.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
    "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2676, 3)\n",
      "TRAIN Dataset: (2141, 3)\n",
      "TEST Dataset: (535, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"FULL Dataset: {}\".format(dataset.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Intents(train_dataset,  w2v_weights_path)\n",
    "testing_set = Intents(test_dataset, w2v_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 4,\n",
    "          'shuffle': True,\n",
    "          'drop_last': True,\n",
    "          'num_workers': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x363c00550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_phrases, sample_labels = next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1595,  0.1243, -0.1276,  ..., -0.0510, -0.2556,  0.1018],\n",
       "        [-0.0557, -0.0601, -0.0634,  ..., -0.0768, -0.0423,  0.0733],\n",
       "        [ 0.0033,  0.0435,  0.1338,  ..., -0.1406, -0.0679,  0.0237],\n",
       "        [-0.0127,  0.0176, -0.1135,  ...,  0.0144, -0.0662, -0.0011]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = torch.zeros((0,300))\n",
    "# train_y = torch.zeros(0, dtype=torch.int64)\n",
    "# for i, (x, y)  in enumerate(training_loader):\n",
    "#     print(\"--- \", i)\n",
    "#     train_x = torch.cat((train_x,x),0)\n",
    "#     train_y = torch.cat((train_y,y),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, inputdim, \n",
    "                        nclasses, \n",
    "                        nhidden, \n",
    "                        dropout = 0,\n",
    "                        cudaEfficient=True):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \n",
    "        self.inputdim = inputdim\n",
    "        self.hidden_dim = nhidden\n",
    "        self.dropout = dropout\n",
    "        self.nclasses = nclasses\n",
    "        \n",
    "        if cudaEfficient:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                ).cuda()\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        log_probs = self.model(x)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = training_set.w2v.vector_size\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "NHIDDEN = 512\n",
    "DROPOUT = 0.3\n",
    "model = SimpleMLP(inputdim = INP_DIM ,\n",
    "          nhidden = NHIDDEN,\n",
    "          nclasses = NUM_LABELS,\n",
    "          dropout = DROPOUT, \n",
    "          cudaEfficient = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)\n",
    "max_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent, label = next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 300]), tensor([118,  45,  32,  73]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 183])\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7650e-02, -3.3532e-02,  2.7905e-02, -2.1228e-03,  4.4209e-02,\n",
       "          5.2014e-02, -1.9360e-02,  5.6161e-04,  1.2432e-02,  8.1035e-03,\n",
       "         -3.4164e-02, -1.9175e-02,  9.5951e-02,  3.2965e-03,  7.3811e-02,\n",
       "          1.9580e-02,  3.9247e-02, -3.9684e-02,  4.1604e-02, -3.2041e-02,\n",
       "          1.8113e-02, -4.1472e-02,  4.8349e-04, -5.9122e-02, -4.8271e-04,\n",
       "          1.6205e-02,  3.4975e-02,  5.5932e-02,  4.3240e-03, -4.2114e-02,\n",
       "         -9.6238e-02, -4.5438e-02, -1.4103e-02, -5.3953e-02, -2.9393e-02,\n",
       "          5.2852e-02, -4.9692e-02,  2.7199e-02, -4.0826e-02,  5.4393e-02,\n",
       "         -6.9761e-02,  5.6748e-02, -5.0887e-02,  3.0244e-02,  2.7098e-02,\n",
       "          1.7302e-02, -6.6278e-02, -5.0661e-02,  1.4504e-02,  1.4668e-03,\n",
       "          5.0174e-02,  1.3245e-02, -1.5151e-02,  2.4367e-02,  9.4287e-03,\n",
       "         -6.9360e-02,  3.2726e-02, -3.6647e-02, -1.8320e-02, -2.7726e-02,\n",
       "          2.8706e-02, -1.5711e-02,  5.0093e-02, -2.3277e-02, -1.9291e-02,\n",
       "         -8.3093e-02, -4.3989e-02, -1.0806e-01,  2.0460e-02,  2.4791e-03,\n",
       "          4.6464e-02, -4.8474e-02,  5.0809e-02, -1.9754e-02, -2.6048e-02,\n",
       "         -5.6502e-02,  3.1750e-02,  1.8407e-02,  1.0964e-02, -5.6720e-02,\n",
       "         -8.7224e-03, -1.0834e-02,  5.5286e-02, -7.0612e-02,  1.1149e-02,\n",
       "         -3.4711e-03, -8.4353e-03, -4.2299e-02, -3.2304e-02,  5.0480e-02,\n",
       "          3.1723e-02,  7.0413e-03, -3.6372e-03,  1.1757e-01, -8.5126e-02,\n",
       "         -5.4180e-02, -1.5083e-02,  9.5259e-02, -7.0817e-02,  4.3455e-02,\n",
       "          2.1328e-03, -2.8701e-02,  1.1251e-01,  7.5182e-02, -3.4034e-02,\n",
       "          6.3376e-02,  7.6354e-02,  4.5294e-02, -5.0361e-02, -2.1221e-02,\n",
       "         -4.6175e-06, -2.6528e-02, -5.8363e-02,  2.2100e-02,  1.2962e-01,\n",
       "          6.9793e-02,  9.2592e-03, -6.5325e-02, -8.8146e-02, -4.2958e-05,\n",
       "          1.8634e-02, -8.8902e-03, -2.3429e-03, -2.0714e-02, -2.1871e-02,\n",
       "         -4.8140e-02, -7.3505e-02, -8.2056e-02, -6.0981e-02, -2.2240e-02,\n",
       "          1.3656e-02,  7.9106e-02, -1.5992e-02,  8.2204e-03,  3.2607e-02,\n",
       "          2.9135e-02, -4.4779e-04, -6.0970e-02, -5.4025e-02, -7.4871e-02,\n",
       "          1.3854e-03,  1.6335e-02, -3.8235e-02, -5.2167e-02,  1.1116e-02,\n",
       "         -3.9061e-02,  3.9039e-03,  4.2613e-02,  5.2303e-02,  5.7407e-02,\n",
       "          4.3698e-02, -6.0223e-02,  7.5188e-02,  6.7995e-03,  1.1935e-03,\n",
       "          2.5775e-02,  5.1255e-02, -2.6410e-02, -3.3744e-02, -1.6348e-02,\n",
       "         -5.6493e-02, -1.1467e-02,  1.2039e-02, -1.1407e-01,  1.9988e-02,\n",
       "         -2.1995e-02,  2.8034e-02, -4.1019e-03, -7.1874e-02,  1.7971e-02,\n",
       "          2.0609e-02, -1.7863e-02, -6.3450e-02,  5.8685e-02, -7.4688e-03,\n",
       "          1.3739e-02,  9.6817e-03, -4.4464e-02, -2.2561e-02,  7.5833e-02,\n",
       "         -2.0248e-02, -2.0081e-02, -6.2862e-02],\n",
       "        [-1.2973e-03,  3.1670e-03,  3.8770e-02, -3.6337e-02,  5.3525e-03,\n",
       "          3.2991e-02, -4.0002e-02,  3.1384e-02, -1.7254e-03,  1.6152e-03,\n",
       "         -2.8363e-02,  1.2167e-02,  5.9532e-02,  1.0865e-02,  2.8052e-02,\n",
       "          5.0817e-02,  6.7199e-02,  1.1281e-02, -2.9599e-02, -6.2533e-02,\n",
       "         -1.7318e-02, -6.8127e-02, -3.3270e-02, -5.2771e-02,  3.3263e-04,\n",
       "         -2.7243e-02,  6.5383e-02,  5.0839e-02,  1.9435e-02, -2.0947e-02,\n",
       "         -2.2012e-02, -1.0383e-02,  7.3623e-03, -9.7724e-03, -3.2807e-02,\n",
       "          4.1656e-02, -3.9777e-02,  4.8506e-02, -4.5959e-02, -6.5391e-03,\n",
       "         -2.0384e-02,  2.6106e-02, -2.7986e-02,  3.0420e-02,  1.6029e-02,\n",
       "         -1.8523e-02,  1.5899e-02, -4.2935e-02,  1.6959e-02,  4.5297e-02,\n",
       "          3.4410e-02, -3.5084e-02, -3.6683e-02,  6.8073e-03, -1.1955e-02,\n",
       "         -8.6543e-02, -2.8002e-02, -7.4107e-02, -4.3944e-02, -4.6590e-02,\n",
       "         -3.3477e-02, -2.8561e-02,  3.6187e-03, -2.2466e-02,  4.2155e-03,\n",
       "         -9.1732e-02, -6.5454e-02, -9.8125e-02, -3.6371e-02,  2.3461e-02,\n",
       "          2.9889e-02, -1.3157e-02,  4.5997e-02,  2.0513e-02, -4.8326e-02,\n",
       "         -3.2169e-02,  6.6625e-02,  4.0349e-03, -1.6250e-02, -6.0196e-03,\n",
       "          3.2239e-03, -3.6434e-02,  1.8052e-02, -5.4294e-02, -5.8020e-03,\n",
       "          4.7807e-02, -2.2913e-02, -5.6854e-02, -2.5739e-02,  4.9050e-02,\n",
       "          1.5801e-02,  4.0312e-02, -1.1472e-02,  4.9500e-02,  2.5078e-03,\n",
       "         -3.0024e-02,  1.9129e-03,  1.3568e-02, -2.1557e-02,  9.8057e-03,\n",
       "         -4.4371e-03, -2.5158e-02,  1.2596e-01,  4.1180e-02,  2.6324e-02,\n",
       "          6.7002e-02,  7.8987e-02,  5.5038e-02, -4.6863e-02,  2.4117e-02,\n",
       "         -5.6694e-03, -9.0829e-03, -3.5044e-02,  2.6570e-03,  5.8389e-02,\n",
       "          7.9503e-02,  8.8554e-03, -8.9146e-02, -2.3111e-02,  9.7223e-03,\n",
       "          2.3117e-02,  1.7260e-02,  2.6986e-03, -3.9765e-02, -3.9345e-02,\n",
       "         -2.3070e-02,  2.6024e-02, -4.9901e-02, -5.1932e-02,  4.2422e-02,\n",
       "         -8.2628e-02,  9.6162e-02,  4.9522e-02, -9.2264e-03, -4.3706e-02,\n",
       "          2.7473e-02, -4.5600e-02, -6.1086e-02, -6.7915e-02, -1.9476e-02,\n",
       "         -7.2182e-03, -5.8032e-02, -3.0743e-02, -4.6134e-02,  2.7807e-02,\n",
       "          3.7764e-03, -4.3879e-02, -6.4023e-04,  3.7422e-02, -2.6543e-02,\n",
       "          2.3305e-02, -1.9890e-03, -1.2832e-03,  5.5400e-02,  6.9488e-02,\n",
       "          8.4761e-03,  3.6874e-02, -1.4367e-02, -1.0252e-02,  1.0874e-02,\n",
       "         -3.9823e-02, -3.4329e-02, -1.9029e-02, -5.0736e-02,  8.6627e-02,\n",
       "          1.9057e-02,  4.2090e-02, -2.5376e-02, -6.2725e-02, -1.6693e-02,\n",
       "         -3.8697e-02,  3.2496e-02,  7.2797e-03,  1.7842e-02,  3.9118e-02,\n",
       "         -3.2628e-02,  1.1120e-02, -4.7445e-02, -9.2019e-03,  3.7541e-02,\n",
       "         -8.2454e-03,  3.6286e-02, -1.5903e-02],\n",
       "        [-2.4772e-02, -1.4566e-02,  2.6206e-02, -1.2807e-02,  7.0650e-02,\n",
       "          6.0853e-02, -9.5234e-02, -2.2597e-02,  7.4923e-03,  5.8480e-02,\n",
       "         -2.1275e-02,  5.1145e-03,  7.4631e-02, -3.8750e-02,  8.0014e-02,\n",
       "          1.5014e-02,  1.1226e-01, -3.7866e-02,  6.9421e-02, -6.8012e-02,\n",
       "         -1.9350e-02, -9.1450e-02,  3.1541e-02, -7.8630e-02, -2.8420e-02,\n",
       "         -1.8179e-02,  7.3781e-02, -1.6571e-02,  2.9667e-02, -1.9799e-02,\n",
       "         -1.7407e-02, -3.3362e-02,  4.6323e-03, -5.7870e-02, -8.3226e-02,\n",
       "          2.5051e-02, -4.3628e-03,  3.6308e-04, -1.9313e-02,  8.6238e-02,\n",
       "         -2.4809e-02, -3.0811e-03, -1.0515e-02,  2.5031e-02,  5.7179e-03,\n",
       "         -3.4352e-02, -1.5274e-02, -7.4707e-02,  2.2428e-03,  2.6332e-02,\n",
       "          5.5445e-02, -2.4198e-02, -2.8041e-02,  2.3187e-02, -1.6329e-02,\n",
       "         -2.2772e-02, -4.0033e-02, -7.6740e-02, -9.7031e-03, -8.9647e-02,\n",
       "         -8.1895e-03, -5.0119e-02,  1.0613e-03, -1.7481e-02,  1.2840e-02,\n",
       "         -1.1752e-01, -6.1483e-02, -1.1126e-01, -1.1848e-02, -1.3396e-02,\n",
       "         -8.5938e-03, -7.5356e-02,  7.0166e-02, -2.5463e-02, -2.7997e-02,\n",
       "         -1.3250e-02,  8.6021e-02, -4.0703e-03, -4.0200e-03, -2.5094e-02,\n",
       "          3.2415e-02,  4.4840e-02,  3.0907e-02, -4.5358e-02,  3.9715e-03,\n",
       "         -3.1293e-02, -2.8086e-02, -4.7048e-02, -4.8868e-02,  6.0445e-02,\n",
       "          2.8583e-02,  3.7857e-02,  4.1661e-02,  9.2081e-02, -1.8607e-02,\n",
       "          1.6856e-02,  6.5362e-04, -5.5676e-02, -2.8707e-02,  5.3592e-02,\n",
       "          2.5583e-02, -1.8059e-02,  1.3105e-01,  3.4682e-03,  1.1921e-04,\n",
       "          4.1568e-02,  5.8385e-02,  9.2823e-02, -7.2059e-02, -1.9621e-02,\n",
       "          1.6930e-05, -1.3755e-02, -9.4876e-02,  7.7054e-03,  7.7327e-02,\n",
       "          5.8660e-02,  4.0670e-02, -7.1529e-02, -1.1121e-01,  4.8037e-02,\n",
       "          6.2478e-03, -6.6075e-03, -2.7799e-02, -5.1375e-02, -1.7330e-02,\n",
       "         -2.1441e-02,  7.2210e-04, -2.0963e-02, -2.1164e-02,  2.1831e-02,\n",
       "         -9.8493e-02,  8.8266e-02,  4.8878e-02, -1.6999e-02, -4.2597e-02,\n",
       "          3.7565e-02, -3.7936e-03, -4.1331e-02, -6.2890e-02, -4.1542e-02,\n",
       "          7.4833e-03, -4.5478e-02, -2.3972e-02, -1.2173e-02,  4.1297e-02,\n",
       "          1.3277e-02,  4.2680e-02, -1.8389e-02,  7.2770e-02, -2.5061e-02,\n",
       "          5.3444e-03, -3.1889e-02,  4.7437e-02,  1.5566e-02,  2.9713e-02,\n",
       "          3.4102e-02,  4.7113e-02, -3.8500e-03, -1.3514e-02, -3.6351e-04,\n",
       "         -2.0783e-02, -1.9034e-02, -9.9610e-03, -4.7762e-02,  1.2758e-01,\n",
       "          1.0188e-02, -3.1276e-02, -9.5344e-02, -8.4241e-02,  1.8618e-02,\n",
       "          1.2777e-02,  2.0051e-02,  3.0016e-03,  4.0767e-02,  8.3927e-02,\n",
       "         -8.1285e-02,  1.9749e-03, -5.9557e-02, -5.5104e-03, -2.1635e-02,\n",
       "         -8.8298e-03,  4.5132e-03, -2.3892e-02],\n",
       "        [-2.4338e-02, -1.9738e-02,  4.2179e-02, -4.9798e-02,  8.4586e-02,\n",
       "          2.4693e-02, -5.9256e-02,  1.8134e-03, -1.5378e-02,  4.9670e-02,\n",
       "         -1.9306e-02, -2.5319e-02,  7.1941e-02,  2.9365e-02,  8.3235e-02,\n",
       "          2.4168e-02,  8.4051e-02, -5.6497e-02, -3.9931e-02, -2.7911e-02,\n",
       "          5.0094e-02, -1.0436e-01,  1.8154e-02, -7.0781e-02, -4.0076e-02,\n",
       "         -1.4791e-02,  6.0194e-02,  1.1994e-02,  1.1832e-02, -5.8854e-02,\n",
       "         -3.7340e-02, -7.2114e-02,  2.0348e-02, -5.2483e-02, -3.6602e-02,\n",
       "         -2.2619e-02, -6.7201e-02,  4.1352e-02, -4.8008e-02,  1.4791e-02,\n",
       "          1.8519e-02,  7.9555e-03, -3.3776e-02, -1.0047e-02,  2.4682e-02,\n",
       "         -4.9439e-02, -1.6728e-02, -3.9195e-02,  1.1780e-02,  1.1073e-02,\n",
       "          4.0936e-02, -5.3199e-02, -9.0689e-03,  1.7483e-02, -2.0990e-02,\n",
       "         -1.0650e-01,  2.3109e-02, -3.3088e-02, -3.8981e-03, -5.9100e-02,\n",
       "         -1.8893e-02,  2.6355e-02,  4.0505e-02, -8.7214e-02, -2.5561e-02,\n",
       "         -5.8678e-02, -7.3170e-02, -5.6122e-02,  2.4142e-03, -1.0357e-02,\n",
       "          5.3729e-02, -3.4290e-02,  6.3784e-02, -7.4393e-02, -3.5267e-02,\n",
       "          3.2376e-02,  1.4475e-02,  1.4594e-02, -1.3492e-02, -7.1054e-02,\n",
       "          7.1512e-02, -2.5718e-02,  7.2621e-02, -5.0415e-02, -2.2854e-02,\n",
       "          4.2051e-02, -2.5850e-03, -2.9371e-03,  1.5916e-02,  6.3079e-02,\n",
       "          3.5239e-02,  5.8093e-03,  5.4635e-02,  1.4093e-01, -4.6782e-02,\n",
       "          2.1381e-02,  6.2521e-03,  4.5937e-02, -1.0763e-01, -1.7894e-02,\n",
       "         -4.5075e-02,  7.1478e-03,  6.7642e-02,  4.1681e-02, -9.7918e-03,\n",
       "          6.2207e-02,  8.1614e-03,  9.0550e-02,  4.8297e-05,  2.1950e-02,\n",
       "         -1.7726e-02, -5.5240e-03, -7.5309e-02,  3.0819e-02,  4.1186e-02,\n",
       "          1.0166e-01,  5.1502e-02, -9.4448e-02, -4.5455e-02,  7.4222e-02,\n",
       "          6.0508e-02, -3.3028e-02, -5.3442e-02, -3.8582e-02, -6.9374e-02,\n",
       "          2.9639e-02,  8.7878e-02, -1.4195e-02, -1.0939e-01,  2.7064e-02,\n",
       "         -4.0320e-02,  1.4150e-01,  5.3980e-02,  2.4469e-02, -1.9085e-02,\n",
       "          4.5351e-02, -2.9011e-03,  5.1226e-03, -9.8118e-02, -3.3840e-02,\n",
       "         -3.2547e-02, -5.1186e-02, -3.0869e-02, -5.8713e-02, -2.0574e-03,\n",
       "         -1.8211e-02,  5.4298e-02,  9.7696e-03, -3.0086e-02,  4.0201e-02,\n",
       "          2.4641e-03, -3.7186e-02, -2.4041e-03,  2.4143e-02,  2.3830e-02,\n",
       "          8.6905e-02,  6.7049e-02, -1.1272e-02, -1.4503e-02, -3.7056e-02,\n",
       "         -2.1006e-02,  3.7889e-03, -2.4127e-03, -2.7326e-02,  1.1320e-01,\n",
       "          3.1221e-02,  6.5406e-02,  3.2624e-02, -7.5629e-02,  3.3216e-02,\n",
       "         -5.8262e-02,  2.4541e-02, -2.3251e-02,  9.0230e-03,  3.0180e-02,\n",
       "         -4.9858e-02,  2.3566e-03, -1.1251e-01,  7.6816e-03, -1.3705e-02,\n",
       "          9.0797e-03, -1.1261e-03,  1.0305e-02]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.forward(sent)\n",
    "print(out.shape)\n",
    "print(label.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2518, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(out, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-41-0caa4c4ca812>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-0caa4c4ca812>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    _, predicted = torch.max(output.data, 1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def train(model, epochs):\n",
    "    max_epochs = epochs\n",
    "    model = model.train()\n",
    "    for epoch in tqdm_notebook(range(max_epochs)):\n",
    "        print(\"EPOCH -- {}\".format(epoch))\n",
    "        for i, (sent, labels) in enumerate(training_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(sent)\n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if i%500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            output = model.forward(ids.cuda(), token_type_ids=tokens.cuda(), head_mask=None)[0]\n",
    "                  _, predicted = torch.max(output.data, 1)\n",
    "                  total += labels.size(0)\n",
    "                  correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "              accuracy = 100.00 * correct.numpy() / total\n",
    "              print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))\n",
    "    return \"Training finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions import base_distributions\n",
    "from gpytorch.likelihoods.likelihood import Likelihood\n",
    "from gpytorch.utils.deprecation import _deprecate_kwarg_with_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLikelihood2(Likelihood):\n",
    "    \"\"\"\n",
    "    Implements the Softmax (multiclass) likelihood used for GP classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_features=None, num_classes=None, mixing_weights=True, mixing_weights_prior=None, **kwargs\n",
    "    ):\n",
    "        num_classes = _deprecate_kwarg_with_transform(\n",
    "            kwargs, \"n_classes\", \"num_classes\", num_classes, lambda n: n\n",
    "        )\n",
    "        super().__init__()\n",
    "        if num_classes is None:\n",
    "            raise ValueError(\"num_classes is required\")\n",
    "        self.num_classes = num_classes\n",
    "        if mixing_weights:\n",
    "            self.num_features = num_features\n",
    "            if num_features is None:\n",
    "                raise ValueError(\"num_features is required with mixing weights\")\n",
    "            self.register_parameter(\n",
    "                name=\"mixing_weights\",\n",
    "                parameter=torch.nn.Parameter(torch.randn(num_classes, num_features).div_(num_features)),\n",
    "            )\n",
    "            if mixing_weights_prior is not None:\n",
    "                self.register_prior(\"mixing_weights_prior\", mixing_weights_prior, \"mixing_weights\")\n",
    "        else:\n",
    "            self.num_features = num_classes\n",
    "            self.mixing_weights = None\n",
    "        print(self.num_features)\n",
    "\n",
    "    def forward(self, function_samples, *params, **kwargs):\n",
    "        num_features, num_data = function_samples.shape[-2:]\n",
    "        if num_features != self.num_features:\n",
    "            raise RuntimeError(\"There should be %d features\" % self.num_features)\n",
    "\n",
    "        if self.mixing_weights is not None:\n",
    "            mixed_fs = self.mixing_weights @ function_samples  # num_classes x num_data\n",
    "        else:\n",
    "            mixed_fs = function_samples\n",
    "        mixed_fs = mixed_fs.transpose(-1, -2)  # num_data x num_classes\n",
    "        res = base_distributions.Categorical(logits=mixed_fs)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import AbstractVariationalGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "from gpytorch.mlls.variational_elbo import VariationalELBO\n",
    "\n",
    "class GPClassificationModel(AbstractVariationalGP):\n",
    "    def __init__(self, train_x):\n",
    "        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, train_x, variational_distribution)\n",
    "        super(GPClassificationModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        return latent_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4a72ecb7b4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize model and likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPClassificationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#likelihood = gpytorch.likelihoods.BernoulliLikelihood()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m likelihood = SoftmaxLikelihood2(num_features=300,\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mmixing_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize model and likelihood\n",
    "model = GPClassificationModel(train_x)\n",
    "#likelihood = gpytorch.likelihoods.BernoulliLikelihood()\n",
    "likelihood = SoftmaxLikelihood2(num_features=300,\n",
    "                                mixing_weights=True,\n",
    "                                num_classes=len(label_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Parameters\n",
    "learning_rate = 0.1\n",
    "max_epochs = 10\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "mll = VariationalELBO(likelihood, model, train_y.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(train_x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-mll(output, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(sent)        \n",
    "        loss = -mll(output, label)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        print('Iter %d/%d - Loss: %.3f' % (i, epoch, loss.item()))\n",
    "        \n",
    "#         if i%100 == 0:\n",
    "#             correct = 0\n",
    "#             total = 0\n",
    "#             for sent, label in testing_loader:\n",
    "#                 sent = Variable(sent)\n",
    "#                 label = Variable(label)\n",
    "#                 output = model.forward(sent)\n",
    "#                 _, predicted = torch.max(output.mean, 1)\n",
    "#                 total += label.size(0)\n",
    "#                 correct += (predicted.cpu() == label.cpu()).sum()\n",
    "#             accuracy = 100.00 * correct.numpy() / total\n",
    "#             print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into eval mode\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test x are regularly spaced by 0.01 0,1 inclusive\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_phrase = \"i need to book a restaurant today\"\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "inp, _ = training_set.get_avg_sentence_vector(input_phrase)\n",
    "inp = torch.tensor(inp)\n",
    "observed_pred = likelihood(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(phrase):\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    inp, _ = training_set.get_avg_sentence_vector(phrase)\n",
    "    inp = torch.Tensor(inp)\n",
    "    output = model.forward(inp)\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "#     # Get predictions from the maximum value\n",
    "#     _, predicted = torch.max(output.data, 0)\n",
    "#     pred_label=list(label_to_ix.keys())[list(label_to_ix.values()).index(predicted.item())]\n",
    "#     return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reply(input_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sources\n",
    "https://gpytorch.readthedocs.io/en/latest/examples/08_Deep_Kernel_Learning/Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bayesian",
   "language": "python",
   "name": "bayesian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
