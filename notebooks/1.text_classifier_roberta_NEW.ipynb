{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "try:\n",
    "    from collections import OrderedDict\n",
    "except ImportError:\n",
    "    from ordereddict import OrderedDict\n",
    "\n",
    "# Torch, Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "\n",
    "## NLP libs\n",
    "from nltk import download\n",
    "import gensim\n",
    "\n",
    "## PyTorch Transformer\n",
    "import transformers\n",
    "\n",
    "## Roberta\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
    "\n",
    "## DistilBert\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
    "from transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "stopwords = {\"ourselves\", \"hers\", \"between\", \"yourself\", \"but\", \"again\", \"there\", \"about\", \"once\", \"during\", \"out\", \"very\", \"having\", \"with\", \"they\", \"own\", \"an\", \"be\", \"some\", \"for\", \"do\", \"its\", \"yours\", \"such\", \"into\", \"of\", \"most\", \"itself\", \"other\", \"off\", \"is\", \"s\", \"am\", \"or\", \"who\", \"as\", \"from\", \"him\", \"each\", \"the\", \"themselves\", \"until\", \"below\", \"are\", \"we\", \"these\", \"your\", \"his\", \"through\", \"don\", \"nor\", \"me\", \"were\", \"her\", \"more\", \"himself\", \"this\", \"down\", \"should\", \"our\", \"their\", \"while\", \"above\", \"both\", \"up\", \"to\", \"ours\", \"had\", \"she\", \"all\", \"no\", \"when\", \"at\", \"any\", \"before\", \"them\", \"same\", \"and\", \"been\", \"have\", \"in\", \"will\", \"on\", \"does\", \"yourselves\", \"then\", \"that\", \"because\", \"what\", \"over\", \"why\", \"so\", \"can\", \"did\", \"not\", \"now\", \"under\", \"he\", \"you\", \"herself\", \"has\", \"just\", \"where\", \"too\", \"only\", \"myself\", \"which\", \"those\", \"i\", \"after\", \"few\", \"whom\", \"t\", \"being\", \"if\", \"theirs\", \"my\", \"against\", \"a\", \"by\", \"doing\", \"it\", \"how\", \"further\", \"was\", \"here\", \"than\"}\n",
    "\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.text_classifier_roberta.ipynb      4.nips2019_papers_simple_altair.ipynb\r\n",
      "1.text_classifier_roberta_NEW.ipynb  4.sample_dpp.ipynb\r\n",
      "2017-06-custom-intent-engines\t     intents_phrases_183.pkl\r\n",
      "2.uncertainty_swag.ipynb\t     intents_phrases_186.pkl\r\n",
      "3.causality_review.ipynb\t     model_elmo_swag_uncertainty.pth\r\n",
      "4.dpp_diversity_phrases.ipynb\t     nips_2018_bert.pkl\r\n",
      "4.dpp_image.ipynb\t\t     nips_2018_elmo.pkl\r\n",
      "4.nips2019_papers.ipynb\t\t     nips_2018.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"intents_phrases_186.pkl\"\n",
    "# dataset = pd.read_pickle(dataset_path)\n",
    "# dataset = dataset.rename(columns={\"usersays\":\"phrase\"})\n",
    "# dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.intent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make shorter version of the dataset\n",
    "# selected_intents = ['position.update',\n",
    "#                     'jobBoard.update',\n",
    "#                     'job.create',\n",
    "#                     'lateralMove',\n",
    "#                     'band.update',\n",
    "#                     'adjustment',\n",
    "#                    'worker.changeManager']\n",
    "# dataset = dataset[dataset.intent.isin(selected_intents)].reset_index(drop=True)\n",
    "# print(len(set(dataset.intent)))\n",
    "# dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: AddToPlaylist, # utterances: 300\n",
      "Class: BookRestaurant, # utterances: 300\n",
      "Class: GetWeather, # utterances: 300\n",
      "Class: PlayMusic, # utterances: 300\n",
      "Class: RateBook, # utterances: 300\n",
      "Class: SearchCreativeWork, # utterances: 300\n",
      "Class: SearchScreeningEvent, # utterances: 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2095</td>\n",
       "      <td>Is Across the Line playing at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2096</td>\n",
       "      <td>Which animated movies are playing in the neigh...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2097</td>\n",
       "      <td>Where is They Always Return at Dawn playing</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2098</td>\n",
       "      <td>What is the movie schedule in the neighborhood</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2099</td>\n",
       "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase                intent\n",
       "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent\n",
       "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent\n",
       "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent\n",
       "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent\n",
       "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = './2017-06-custom-intent-engines/'\n",
    "## Another dataset\n",
    "dataset = pd.DataFrame(columns = ['utterance', 'label'])\n",
    "for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "               'SearchScreeningEvent']:\n",
    "    with open(dataset_path + intent + \"/train_\" + intent + \".json\",\n",
    "              encoding='cp1251') as data_file:\n",
    "        data = json.load(data_file)\n",
    "    print(\"Class: {}, # utterances: {}\".format(intent,len(data[intent])))\n",
    "    texts = []\n",
    "    for i in range(len(data[intent])):\n",
    "        text = ''\n",
    "        for j in range(len(data[intent][i]['data'])):\n",
    "            text += data[intent][i]['data'][j]['text']\n",
    "        dataset = dataset.append({'utterance': text, 'label': intent}, ignore_index=True)\n",
    "dataset = dataset.rename(columns={\"utterance\":\"phrase\", \"label\":\"intent\"})\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_dataset(dataframe,\n",
    "                     label_column = 'intent',\n",
    "                     feature_column = 'phrase',\n",
    "                     max_samples = 100):\n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN\n",
    "\n",
    "    ## Build label vocabulary\n",
    "    label_to_ix = {}\n",
    "    for label in dataset[label_column]:\n",
    "        for word in label.split():\n",
    "            if word not in label_to_ix:\n",
    "                label_to_ix[word]=len(label_to_ix)\n",
    "          \n",
    "    ## Define Sampling Strategy based on number of samples\n",
    "    classes_sample = {}\n",
    "    for cls in list(set(label_to_ix.values())):\n",
    "        classes_sample.update({cls:max_samples})\n",
    "\n",
    "    sampler = RandomOverSampler(sampling_strategy = classes_sample, random_state=42)\n",
    "    x = np.array(dataset.index).reshape(-1, 1)\n",
    "    y = np.array(list(dataset[label_column].apply(lambda x: label_to_ix[x])))\n",
    "    \n",
    "    ## Oversampling\n",
    "    x_resampled, y_resampled = sampler.fit_sample(x, y)\n",
    "    dataset_resampled = pd.DataFrame(columns=[feature_column,label_column])\n",
    "    \n",
    "    ## Iterating\n",
    "    for i, item in enumerate(x_resampled):\n",
    "        row = {\n",
    "            feature_column :dataset[feature_column].loc[item[0]],\n",
    "            label_column: list(label_to_ix.keys())[y_resampled[i]]\n",
    "        }\n",
    "        dataset_resampled = dataset_resampled.append(row, ignore_index=True)\n",
    "    return dataset_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset = resample_dataset(dataset, max_samples = 300)\n",
    "# dataset.intent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2095</td>\n",
       "      <td>Is Across the Line playing at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2096</td>\n",
       "      <td>Which animated movies are playing in the neigh...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2097</td>\n",
       "      <td>Where is They Always Return at Dawn playing</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2098</td>\n",
       "      <td>What is the movie schedule in the neighborhood</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2099</td>\n",
       "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase                intent\n",
       "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent\n",
       "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent\n",
       "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent\n",
       "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent\n",
       "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Cleaning input\n",
    "    text = text.replace(\"'s\",\"\")\n",
    "    text = text.replace(\"â€™s\",\"\")\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"-\",\"\")\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Removing all the stopwords\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stopwords]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2095</td>\n",
       "      <td>Is Across the Line playing at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>across line playing closest movie house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2096</td>\n",
       "      <td>Which animated movies are playing in the neigh...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>animated movies playing neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2097</td>\n",
       "      <td>Where is They Always Return at Dawn playing</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>always return dawn playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2098</td>\n",
       "      <td>What is the movie schedule in the neighborhood</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>movie schedule neighborhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2099</td>\n",
       "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>tell howling ii sister werewolf playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase                intent  \\\n",
       "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent   \n",
       "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent   \n",
       "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent   \n",
       "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent   \n",
       "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent   \n",
       "\n",
       "                                  preproc_text  \n",
       "2095   across line playing closest movie house  \n",
       "2096     animated movies playing neighbourhood  \n",
       "2097                always return dawn playing  \n",
       "2098               movie schedule neighborhood  \n",
       "2099  tell howling ii sister werewolf playing   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['preproc_text'] = dataset['phrase'].apply(lambda x: transformText(x, do_stop=True))\n",
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Labels: 7\n"
     ]
    }
   ],
   "source": [
    "## Build label vocabulary\n",
    "label_to_ix = {}\n",
    "for label in dataset.intent:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)\n",
    "print(\"# Labels: {}\".format(len(label_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa\n",
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 7,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = 'roberta'\n",
    "## Distilbert\n",
    "if model_type == 'distilbert':\n",
    "    print(\"DistilBERT\")\n",
    "    config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "    config.num_labels = len(list(label_to_ix.values()))\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification(config)\n",
    "    print(config)\n",
    "elif model_type == 'roberta':\n",
    "    print(\"RoBERTa\")\n",
    "    config = RobertaConfig.from_pretrained('roberta-base')\n",
    "    config.num_labels = len(list(label_to_ix.values()))\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaForSequenceClassification(config)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(seq_1, zero_pad = False, max_seq_length = 300):\n",
    "    enc_text = tokenizer.encode_plus(seq_1, add_special_tokens=True, max_length=300)\n",
    "    if zero_pad:\n",
    "        while len(enc_text['input_ids']) < max_seq_length:\n",
    "            enc_text['input_ids'].append(0)\n",
    "            enc_text['token_type_ids'].append(0)\n",
    "    return enc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'special_tokens_mask': [1, 0, 0, 0, 1],\n",
       " 'input_ids': [0,\n",
       "  33959,\n",
       "  42,\n",
       "  2638,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_features(\"testing this loved\", zero_pad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.preproc_text[index]\n",
    "        label = self.data.intent[index]\n",
    "        X = prepare_features(utterance, zero_pad = True)\n",
    "        y = label_to_ix[self.data.intent[index]]\n",
    "        return np.array(X['input_ids']), np.array(X['token_type_ids']), y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>I want to see a list of the closest cinema's m...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>want see list closest cinema movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2091</td>\n",
       "      <td>What Are the showings for The Natural History ...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>showings natural history parking lots movie house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2092</td>\n",
       "      <td>Give me the schedule for Public Stenographer a...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>give schedule public stenographer mjr theatres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2093</td>\n",
       "      <td>Is it possible to see Tube at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>possible see tube closest movie theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2094</td>\n",
       "      <td>I want to see Wenn Lucy springt now at a movie...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>want see wenn lucy springt movie theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2095</td>\n",
       "      <td>Is Across the Line playing at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>across line playing closest movie house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2096</td>\n",
       "      <td>Which animated movies are playing in the neigh...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>animated movies playing neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2097</td>\n",
       "      <td>Where is They Always Return at Dawn playing</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>always return dawn playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2098</td>\n",
       "      <td>What is the movie schedule in the neighborhood</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>movie schedule neighborhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2099</td>\n",
       "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>tell howling ii sister werewolf playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase                intent  \\\n",
       "2090  I want to see a list of the closest cinema's m...  SearchScreeningEvent   \n",
       "2091  What Are the showings for The Natural History ...  SearchScreeningEvent   \n",
       "2092  Give me the schedule for Public Stenographer a...  SearchScreeningEvent   \n",
       "2093  Is it possible to see Tube at the closest movi...  SearchScreeningEvent   \n",
       "2094  I want to see Wenn Lucy springt now at a movie...  SearchScreeningEvent   \n",
       "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent   \n",
       "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent   \n",
       "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent   \n",
       "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent   \n",
       "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent   \n",
       "\n",
       "                                           preproc_text  \n",
       "2090                want see list closest cinema movies  \n",
       "2091  showings natural history parking lots movie house  \n",
       "2092     give schedule public stenographer mjr theatres  \n",
       "2093           possible see tube closest movie theatre   \n",
       "2094          want see wenn lucy springt movie theatre   \n",
       "2095            across line playing closest movie house  \n",
       "2096              animated movies playing neighbourhood  \n",
       "2097                         always return dawn playing  \n",
       "2098                        movie schedule neighborhood  \n",
       "2099           tell howling ii sister werewolf playing   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4195</td>\n",
       "      <td>Add Fair Charlotte to the We Everywhere playlist.</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add fair charlotte everywhere playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4196</td>\n",
       "      <td>Start playing anything Mike Muir made in the t...</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>start playing anything mike muir made thirties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4197</td>\n",
       "      <td>Please look up for the work, Black Box.</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>please look work black box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4198</td>\n",
       "      <td>give this textbook a four</td>\n",
       "      <td>RateBook</td>\n",
       "      <td>give textbook four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4199</td>\n",
       "      <td>Book me a reservation for six for Crown Burger...</td>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>book reservation six crown burgers lebanon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase              intent  \\\n",
       "4195  Add Fair Charlotte to the We Everywhere playlist.       AddToPlaylist   \n",
       "4196  Start playing anything Mike Muir made in the t...           PlayMusic   \n",
       "4197            Please look up for the work, Black Box.  SearchCreativeWork   \n",
       "4198                          give this textbook a four            RateBook   \n",
       "4199  Book me a reservation for six for Crown Burger...      BookRestaurant   \n",
       "\n",
       "                                        preproc_text  \n",
       "4195         add fair charlotte everywhere playlist   \n",
       "4196  start playing anything mike muir made thirties  \n",
       "4197                     please look work black box   \n",
       "4198                              give textbook four  \n",
       "4199      book reservation six crown burgers lebanon  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "dataset = pd.concat([dataset, dataset]).reset_index(drop=True)\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dataset.sample(frac=train_size,random_state=42).reset_index(drop=True)\n",
    "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Intents(train_dataset)\n",
    "testing_set = Intents(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlayMusic               496\n",
       "SearchScreeningEvent    490\n",
       "GetWeather              482\n",
       "RateBook                481\n",
       "SearchCreativeWork      479\n",
       "AddToPlaylist           467\n",
       "BookRestaurant          465\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.intent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchScreeningEvent    135\n",
       "PlayMusic               127\n",
       "SearchCreativeWork      120\n",
       "GetWeather              119\n",
       "RateBook                116\n",
       "BookRestaurant          115\n",
       "AddToPlaylist           108\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.intent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is AVAILABLE!ðŸ¤˜ðŸ™ŒðŸ’ª\n"
     ]
    }
   ],
   "source": [
    "### Dataloaders Parameters\n",
    "params = {'batch_size': 2,\n",
    "          'shuffle': True,\n",
    "          'drop_last': True,\n",
    "          'num_workers': 0}\n",
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is AVAILABLE!ðŸ¤˜ðŸ™ŒðŸ’ª\")\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 300]), torch.Size([2, 300]), torch.Size([2]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, tokens, labels = next(iter(training_loader))\n",
    "ids.shape, tokens.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 300])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa\n",
      "tensor(1.7798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([2, 7])\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'roberta':\n",
    "    print(\"RoBERTa\")\n",
    "    out = model.forward(ids.cuda(), token_type_ids=tokens.cuda(), head_mask=None)[0]\n",
    "elif model_type == 'distilbert':\n",
    "    print(\"DistilBERT\")\n",
    "    out = model.forward(ids.cuda())[0]\n",
    "print(loss_function(out, labels.cuda()))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e75877440624197b7a488459ca3ca70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "Iteration: 0. Loss: 1.8866183757781982. Accuracy: 15.238095238095237%\n",
      "Iteration: 100. Loss: 2.311615228652954. Accuracy: 14.166666666666666%\n",
      "Iteration: 200. Loss: 1.6845951080322266. Accuracy: 12.738095238095237%\n",
      "Iteration: 300. Loss: 2.2933998107910156. Accuracy: 14.166666666666666%\n",
      "Iteration: 400. Loss: 1.884190559387207. Accuracy: 13.333333333333334%\n",
      "Iteration: 500. Loss: 2.0379934310913086. Accuracy: 13.69047619047619%\n",
      "Iteration: 600. Loss: 2.385106086730957. Accuracy: 14.166666666666666%\n",
      "Iteration: 700. Loss: 1.9154937267303467. Accuracy: 14.404761904761905%\n",
      "Iteration: 800. Loss: 2.3012232780456543. Accuracy: 13.69047619047619%\n",
      "Iteration: 900. Loss: 1.8624022006988525. Accuracy: 17.261904761904763%\n",
      "Iteration: 1000. Loss: 1.983472466468811. Accuracy: 13.333333333333334%\n",
      "Iteration: 1100. Loss: 2.1209373474121094. Accuracy: 14.285714285714286%\n",
      "Iteration: 1200. Loss: 2.0511763095855713. Accuracy: 15.833333333333334%\n",
      "Iteration: 1300. Loss: 1.8092669248580933. Accuracy: 14.761904761904763%\n",
      "Iteration: 1400. Loss: 2.095803737640381. Accuracy: 12.619047619047619%\n",
      "Iteration: 1500. Loss: 1.686845302581787. Accuracy: 17.38095238095238%\n",
      "Iteration: 1600. Loss: 1.9017305374145508. Accuracy: 15.357142857142858%\n",
      "EPOCH -- 1\n",
      "Iteration: 0. Loss: 2.089395523071289. Accuracy: 16.19047619047619%\n",
      "Iteration: 100. Loss: 1.7322441339492798. Accuracy: 15.595238095238095%\n",
      "Iteration: 200. Loss: 1.6933603286743164. Accuracy: 14.761904761904763%\n",
      "Iteration: 300. Loss: 1.7546603679656982. Accuracy: 14.285714285714286%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (ids, tokens, labels) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if torch.cuda.is_available():\n",
    "            ids = ids.cuda()\n",
    "            tokens = tokens.cuda()\n",
    "            labels = labels.cuda()\n",
    "        if model_type == 'roberta':\n",
    "            output = model.forward(ids,token_type_ids=tokens)[0]\n",
    "        elif model_type == 'distilbert':\n",
    "            output = model.forward(ids)[0]\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for (ids, tokens, labels) in testing_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    ids = ids.cuda()\n",
    "                    tokens = tokens.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                if model_type == 'roberta':\n",
    "                    output = model.forward(ids,token_type_ids=tokens)[0]\n",
    "                elif model_type == 'distilbert':\n",
    "                    output = model.forward(ids)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "| Model     | LR       | Batch Size   | Epochs    | Accuracy    |\n",
    "| :---:     | :---:    | :---:        | :---:     |  :---:      |\n",
    "| RoBERTa   |   1e-05  |     2        |    5      |   97.73%    | \n",
    "| RoBERTa   |   1e-05  |     4        |    5      |   98.57%    | \n",
    "| RoBERTa   |   2e-05  |     2        |    5      |          | \n",
    "| RoBERTa   |   2e-05  |     4        |    5      |          | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"radiohead playlist\"\n",
    "input_msg = prepare_features(msg, zero_pad=True)\n",
    "ids = torch.tensor(input_msg['input_ids'])\n",
    "tokens = torch.tensor(input_msg['token_type_ids'])\n",
    "ids\n",
    "out = model.forward(ids.cuda(),token_type_ids=tokens.cuda())\n",
    "\n",
    "#model.forward(input_msg['input_ids'],token_type_ids=input_msg['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(msg):\n",
    "    model.eval()\n",
    "    input_msg, _ = prepare_features(msg)\n",
    "    if torch.cuda.is_available():\n",
    "        input_msg = input_msg.cuda()\n",
    "    output = model(input_msg)[0]\n",
    "    _, pred_label = torch.max(output.data, 1)\n",
    "    prediction=list(label_to_ix.keys())[pred_label]\n",
    "    return prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
