{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "try:\n",
    "    from collections import OrderedDict\n",
    "except ImportError:\n",
    "    from ordereddict import OrderedDict\n",
    "\n",
    "# Torch, Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "\n",
    "## NLP libs\n",
    "from nltk import download\n",
    "import gensim\n",
    "\n",
    "## PyTorch Transformer\n",
    "import transformers\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
    "from transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "\n",
    "stopwords = {\"ourselves\", \"hers\", \"between\", \"yourself\", \"but\", \"again\", \"there\", \"about\", \"once\", \"during\", \"out\", \"very\", \"having\", \"with\", \"they\", \"own\", \"an\", \"be\", \"some\", \"for\", \"do\", \"its\", \"yours\", \"such\", \"into\", \"of\", \"most\", \"itself\", \"other\", \"off\", \"is\", \"s\", \"am\", \"or\", \"who\", \"as\", \"from\", \"him\", \"each\", \"the\", \"themselves\", \"until\", \"below\", \"are\", \"we\", \"these\", \"your\", \"his\", \"through\", \"don\", \"nor\", \"me\", \"were\", \"her\", \"more\", \"himself\", \"this\", \"down\", \"should\", \"our\", \"their\", \"while\", \"above\", \"both\", \"up\", \"to\", \"ours\", \"had\", \"she\", \"all\", \"no\", \"when\", \"at\", \"any\", \"before\", \"them\", \"same\", \"and\", \"been\", \"have\", \"in\", \"will\", \"on\", \"does\", \"yourselves\", \"then\", \"that\", \"because\", \"what\", \"over\", \"why\", \"so\", \"can\", \"did\", \"not\", \"now\", \"under\", \"he\", \"you\", \"herself\", \"has\", \"just\", \"where\", \"too\", \"only\", \"myself\", \"which\", \"those\", \"i\", \"after\", \"few\", \"whom\", \"t\", \"being\", \"if\", \"theirs\", \"my\", \"against\", \"a\", \"by\", \"doing\", \"it\", \"how\", \"further\", \"was\", \"here\", \"than\"}\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.text_classifier_roberta.ipynb      4.nips2019_papers_simple_altair.ipynb\r\n",
      "1.text_classifier_roberta_NEW.ipynb  4.sample_dpp.ipynb\r\n",
      "2017-06-custom-intent-engines\t     intents_phrases_183.pkl\r\n",
      "2.uncertainty_swag.ipynb\t     model_elmo_swag_uncertainty.pth\r\n",
      "3.causality_review.ipynb\t     nips_2018_bert.pkl\r\n",
      "4.dpp_diversity_phrases.ipynb\t     nips_2018_elmo.pkl\r\n",
      "4.dpp_image.ipynb\t\t     nips_2018.pkl\r\n",
      "4.nips2019_papers.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2671</td>\n",
       "      <td>modify her military information</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2672</td>\n",
       "      <td>modify worker military status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2673</td>\n",
       "      <td>change employee veteran status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2674</td>\n",
       "      <td>change his military status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>update Brian's veteran status</td>\n",
       "      <td>workerVeteranStatus.update</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               phrase                      intent\n",
       "2671  modify her military information  workerVeteranStatus.update\n",
       "2672    modify worker military status  workerVeteranStatus.update\n",
       "2673   change employee veteran status  workerVeteranStatus.update\n",
       "2674       change his military status  workerVeteranStatus.update\n",
       "2675    update Brian's veteran status  workerVeteranStatus.update"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_pickle('intents_phrases_183.pkl')\n",
    "dataset = dataset.rename(columns={\"usersays\":\"phrase\"})\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['candidate.refer',\n",
       " 'vendor.update',\n",
       " 'job.deactivate',\n",
       " 'compensationPlanStep.delete',\n",
       " 'payGrade.activate',\n",
       " 'personHeight.update',\n",
       " 'person.create',\n",
       " 'payGrade.deactivate',\n",
       " 'workerPersonalEmail.update',\n",
       " 'level.delete',\n",
       " 'workerClockOut.record',\n",
       " 'moneyDistributionInstruction.update',\n",
       " 'campus.update',\n",
       " 'workerSocialNetwork.update',\n",
       " 'associateGovernmentRegistration.update',\n",
       " 'jobReferral.hold',\n",
       " 'worker.retire',\n",
       " 'workerVeteranStatus.update',\n",
       " 'jobRequisition.cancel',\n",
       " 'assessment.update',\n",
       " 'legalEntity.close',\n",
       " 'worker.hire',\n",
       " 'vendor.deactivate',\n",
       " 'assessment.submit',\n",
       " 'jobReferral.evaluate',\n",
       " 'vendor.delete',\n",
       " 'password.update',\n",
       " 'position.update',\n",
       " 'jobRequisition.create',\n",
       " 'assessment.take',\n",
       " 'workerDeathDate.inform',\n",
       " 'evaluation.update',\n",
       " 'jobRequisition.hold',\n",
       " 'workerPersonalContacts.update',\n",
       " 'helper.intents',\n",
       " 'campus.delete',\n",
       " 'personGovernmentRegistration.update',\n",
       " 'jobBoard.update',\n",
       " 'associateGovernmentRegistration.create',\n",
       " 'jobFamily.delete',\n",
       " 'jobReferral.payment',\n",
       " 'workerGender.update',\n",
       " 'personDisability.update',\n",
       " 'jobBoard.delete',\n",
       " 'job.create',\n",
       " 'worker.changePosition',\n",
       " 'jobSearch.update',\n",
       " 'personDeathDate.inform',\n",
       " 'personVeteranStatus.update',\n",
       " 'logout',\n",
       " 'personGovernmentRegistration.create',\n",
       " 'lateralMove',\n",
       " 'personPersonalEmail.update',\n",
       " 'workerPersonalAddress.update',\n",
       " 'location.create',\n",
       " 'worker.usI9Screening.section1.complete',\n",
       " 'personEthnicity.update',\n",
       " 'worker.resign',\n",
       " 'workerLGBT.update',\n",
       " 'helper.questions',\n",
       " 'jobApplication.reject',\n",
       " 'compensationPlan.create',\n",
       " 'jobPosting.update',\n",
       " 'level.deactivate',\n",
       " 'evaluation.review',\n",
       " 'workerStartDate.update',\n",
       " 'externalJobApplication.submit',\n",
       " 'workerBirthInformation.update',\n",
       " 'jobBoard.create',\n",
       " 'location.read',\n",
       " 'jobSearch.delete',\n",
       " 'evaluation.schedule',\n",
       " 'view.job',\n",
       " 'workerName.update',\n",
       " 'data.import',\n",
       " 'worker.changeLevel',\n",
       " 'worker.usI9Screening.section1.generate',\n",
       " 'internalJobApplication.submit',\n",
       " 'personCitizenship.update',\n",
       " 'worker.usI9Screening.section2.generate',\n",
       " 'jobRequisition.update',\n",
       " 'level.activate',\n",
       " 'personLGBT.update',\n",
       " 'legalEntity.update',\n",
       " 'personSocialNetwork.update',\n",
       " 'workerEthnicity.update',\n",
       " 'jobApplication.evaluate',\n",
       " 'jobFamily.update',\n",
       " 'band.update',\n",
       " 'jobRequisition.activate',\n",
       " 'personPersonalContacts.update',\n",
       " 'worker.usI9Screening.status.update',\n",
       " 'workerBloodGroup.update',\n",
       " 'location.delete',\n",
       " 'position.delete',\n",
       " 'workerDisability.update',\n",
       " 'workerMaritalStatus.update',\n",
       " 'jobFamily.create',\n",
       " 'jobRequisition.close',\n",
       " 'personStudentStatus.update',\n",
       " 'job.update',\n",
       " 'personBloodGroup.update',\n",
       " 'personMaritalStatus.update',\n",
       " 'compensationPlan.delete',\n",
       " 'workerBusinessContactInformation.update',\n",
       " 'jobFamily.activate',\n",
       " 'workerCitizenship.update',\n",
       " 'jobFamily.deactivate',\n",
       " 'legalEntity.deactivate',\n",
       " 'question.detect',\n",
       " 'compensationPlanStep.update',\n",
       " 'workAssignment.create',\n",
       " 'vendor.activate',\n",
       " 'personTobaccoUsageStatus.update',\n",
       " 'workerTobaccoUsageStatus.update',\n",
       " 'adjustment',\n",
       " 'helper.commands',\n",
       " 'compensationPlan.update',\n",
       " 'positionRelationships.update',\n",
       " 'band.delete',\n",
       " 'position.create',\n",
       " 'paymentDate.update',\n",
       " 'personPersonalPhoneNumber.update',\n",
       " 'workerPersonalPhoneNumber.update',\n",
       " 'workerStudentStatus.update',\n",
       " 'legalEntity.create',\n",
       " 'worker.changeManager',\n",
       " 'jobOffer.evaluate',\n",
       " 'personPersonalAddress.update',\n",
       " 'team.update',\n",
       " 'transfer',\n",
       " 'job.delete',\n",
       " 'jobApplicationInterest.confirm',\n",
       " 'jobSearch.create',\n",
       " 'worker.usI9Screening.section2.complete',\n",
       " 'jobOffer.create',\n",
       " 'level.update',\n",
       " 'worker.changeJob',\n",
       " 'my.todos',\n",
       " 'termination.revoke',\n",
       " 'payGrade.update',\n",
       " 'legalEntity.delete',\n",
       " 'promote',\n",
       " 'smalltalk',\n",
       " 'band.create',\n",
       " 'team.create',\n",
       " 'demote',\n",
       " 'jobApplication.withdraw',\n",
       " 'jobOffer.revoke',\n",
       " 'personGender.update',\n",
       " 'location.deactivate',\n",
       " 'campus.create',\n",
       " 'compensationPlanStep.create',\n",
       " 'payGrade.delete',\n",
       " 'jobPosting.create',\n",
       " 'resign.revoke',\n",
       " 'evaluation.cancel',\n",
       " 'level.create',\n",
       " 'personBirthInformation.update',\n",
       " 'position.deactivate',\n",
       " 'vendor.create',\n",
       " 'worker.changeOrganization',\n",
       " 'jobReferral.activate',\n",
       " 'worker.terminate',\n",
       " 'assessment.add',\n",
       " 'legalEntity.activate',\n",
       " 'jobPosting.cancel',\n",
       " 'personName.update',\n",
       " 'workerHeight.update',\n",
       " 'workerIndicativeData.verify',\n",
       " 'payGrade.create',\n",
       " 'location.activate',\n",
       " 'jobApplication.update',\n",
       " 'jobReferral.cancel',\n",
       " 'job.activate',\n",
       " 'us.taxWithholding.update',\n",
       " 'band.deactivate',\n",
       " 'position.activate',\n",
       " 'associateWageGarnishmentInstruction.create',\n",
       " 'jobRequisitionRecruiter.assign',\n",
       " 'band.activate',\n",
       " 'payrollSchedulePractitioner.assign',\n",
       " 'location.update']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(dataset.intent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>modify worker overtime pay</td>\n",
       "      <td>adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>adjust Andy bonus</td>\n",
       "      <td>adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>update bonus</td>\n",
       "      <td>adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>change associate regular pay</td>\n",
       "      <td>adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>change Tom salary</td>\n",
       "      <td>adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>new manager for Martha</td>\n",
       "      <td>worker.changeManager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>Katherine boss change</td>\n",
       "      <td>worker.changeManager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>Katherine manager changed</td>\n",
       "      <td>worker.changeManager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>Nick manager update</td>\n",
       "      <td>worker.changeManager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>Katherine modify boss</td>\n",
       "      <td>worker.changeManager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          phrase                intent\n",
       "0     modify worker overtime pay            adjustment\n",
       "1              adjust Andy bonus            adjustment\n",
       "2                   update bonus            adjustment\n",
       "3   change associate regular pay            adjustment\n",
       "4              change Tom salary            adjustment\n",
       "..                           ...                   ...\n",
       "86        new manager for Martha  worker.changeManager\n",
       "87         Katherine boss change  worker.changeManager\n",
       "88     Katherine manager changed  worker.changeManager\n",
       "89           Nick manager update  worker.changeManager\n",
       "90         Katherine modify boss  worker.changeManager\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make shorter version of the dataset\n",
    "selected_intents = ['position.update',\n",
    "                    'jobBoard.update',\n",
    "                    'job.create',\n",
    "                    'lateralMove',\n",
    "                    'band.update',\n",
    "                    'adjustment',\n",
    "                   'worker.changeManager']\n",
    "dataset = dataset[dataset.intent.isin(selected_intents)].reset_index(drop=True)\n",
    "print(len(set(dataset.intent)))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddToPlaylist\tGetWeather  RateBook   SearchCreativeWork\r\n",
      "BookRestaurant\tPlayMusic   README.md  SearchScreeningEvent\r\n"
     ]
    }
   ],
   "source": [
    "!ls 2017-06-custom-intent-engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = './2017-06-custom-intent-engines/'\n",
    "# ## Another dataset\n",
    "# dataset = pd.DataFrame(columns = ['utterance', 'label'])\n",
    "# for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "#                'SearchScreeningEvent']:\n",
    "#     with open(dataset_path + intent + \"/train_\" + intent + \".json\",\n",
    "#               encoding='cp1251') as data_file:\n",
    "#         data = json.load(data_file)\n",
    "#     print(\"Class: {}, # utterances: {}\".format(intent,len(data[intent])))\n",
    "#     texts = []\n",
    "#     for i in range(len(data[intent])):\n",
    "#         text = ''\n",
    "#         for j in range(len(data[intent][i]['data'])):\n",
    "#             text += data[intent][i]['data'][j]['text']\n",
    "#         dataset = dataset.append({'utterance': text, 'label': intent}, ignore_index=True)\n",
    "# dataset = dataset.rename(columns={\"utterance\":\"phrase\", \"label\":\"intent\"})\n",
    "# dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Cleaning input\n",
    "    text = text.replace(\"'s\",\"\")\n",
    "    text = text.replace(\"’s\",\"\")\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"-\",\"\")\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Removing all the stopwords\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stopwords]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>new manager for Martha</td>\n",
       "      <td>worker.changeManager</td>\n",
       "      <td>new manager martha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>Katherine boss change</td>\n",
       "      <td>worker.changeManager</td>\n",
       "      <td>katherine boss change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>Katherine manager changed</td>\n",
       "      <td>worker.changeManager</td>\n",
       "      <td>katherine manager changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>Nick manager update</td>\n",
       "      <td>worker.changeManager</td>\n",
       "      <td>nick manager update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>Katherine modify boss</td>\n",
       "      <td>worker.changeManager</td>\n",
       "      <td>katherine modify boss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phrase                intent               preproc_text\n",
       "86     new manager for Martha  worker.changeManager         new manager martha\n",
       "87      Katherine boss change  worker.changeManager      katherine boss change\n",
       "88  Katherine manager changed  worker.changeManager  katherine manager changed\n",
       "89        Nick manager update  worker.changeManager        nick manager update\n",
       "90      Katherine modify boss  worker.changeManager      katherine modify boss"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['preproc_text'] = dataset['phrase'].apply(lambda x: transformText(x, do_stop=True))\n",
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Labels: 7\n"
     ]
    }
   ],
   "source": [
    "## Build label vocabulary\n",
    "label_to_ix = {}\n",
    "for label in dataset.intent:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)\n",
    "print(\"# Labels: {}\".format(len(label_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 7,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pruned_heads\": {},\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained('roberta-base')\n",
    "config.num_labels = len(list(label_to_ix.values()))\n",
    "#config.num_hidden_layers = 24\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(seq_1, zero_pad = False, max_seq_length = 300):\n",
    "    enc_text = tokenizer.encode_plus(seq_1, add_special_tokens=True, max_length=300)\n",
    "    if zero_pad:\n",
    "        while len(enc_text['input_ids']) < max_seq_length:\n",
    "            enc_text['input_ids'].append(0)\n",
    "            enc_text['token_type_ids'].append(0)\n",
    "    return enc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'special_tokens_mask': [1, 0, 0, 0, 1],\n",
       " 'input_ids': [0,\n",
       "  33959,\n",
       "  42,\n",
       "  2638,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_features(\"testing this loved\", zero_pad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.preproc_text[index]\n",
    "        label = self.data.intent[index]\n",
    "        X = prepare_features(utterance, zero_pad = True)\n",
    "        y = label_to_ix[self.data.intent[index]]\n",
    "        return np.array(X['input_ids']), np.array(X['token_type_ids']), y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "dataset = pd.concat([dataset, dataset]).reset_index(drop=True)\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataset=dataset.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
    "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)\n",
    "\n",
    "training_set = Intents(train_dataset)\n",
    "testing_set = Intents(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders Parameters\n",
    "params = {'batch_size': 2,\n",
    "          'shuffle': True,\n",
    "          'drop_last': True,\n",
    "          'num_workers': 0}\n",
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 300]), torch.Size([2, 300]), torch.Size([2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, tokens, labels = next(iter(training_loader))\n",
    "ids.shape, tokens.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 300])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0553, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.forward(ids.cuda(),token_type_ids=tokens.cuda(), head_mask=None)[0]\n",
    "loss_function(out, labels.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e7b34cee92462a8063073fa944e169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "Iteration: 0. Loss: 1.9274846315383911. Accuracy: 19.444444444444443%\n",
      "EPOCH -- 1\n",
      "Iteration: 0. Loss: 1.8084068298339844. Accuracy: 19.444444444444443%\n",
      "EPOCH -- 2\n",
      "Iteration: 0. Loss: 2.0061216354370117. Accuracy: 16.666666666666668%\n",
      "EPOCH -- 3\n",
      "Iteration: 0. Loss: 1.8913463354110718. Accuracy: 22.22222222222222%\n",
      "EPOCH -- 4\n",
      "Iteration: 0. Loss: 1.7564842700958252. Accuracy: 19.444444444444443%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (ids, tokens, labels) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if torch.cuda.is_available():\n",
    "            ids = ids.cuda()\n",
    "            tokens = tokens.cuda()\n",
    "            labels = labels.cuda()\n",
    "        output = model.forward(ids,token_type_ids=tokens)[0]\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for (ids, tokens, labels) in testing_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    ids = ids.cuda()\n",
    "                    tokens = tokens.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                output = model.forward(ids,token_type_ids=tokens)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"radiohead playlist\"\n",
    "input_msg = prepare_features(msg, zero_pad=True)\n",
    "ids = torch.tensor(input_msg['input_ids'])\n",
    "tokens = torch.tensor(input_msg['token_type_ids'])\n",
    "ids\n",
    "out = model.forward(ids.cuda(),token_type_ids=tokens.cuda())\n",
    "\n",
    "#model.forward(input_msg['input_ids'],token_type_ids=input_msg['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(msg):\n",
    "    model.eval()\n",
    "    input_msg, _ = prepare_features(msg)\n",
    "    if torch.cuda.is_available():\n",
    "        input_msg = input_msg.cuda()\n",
    "    output = model(input_msg)[0]\n",
    "    _, pred_label = torch.max(output.data, 1)\n",
    "    prediction=list(label_to_ix.keys())[pred_label]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Example - Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.phrase[index]\n",
    "        label = self.data.intent[index]\n",
    "        X, _  = prepare_features(utterance)\n",
    "        y = label_to_ix[self.data.intent[index]]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(seq_1, max_seq_length = 300, \n",
    "             zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    tokens_a = tokenizer.tokenize(seq_1)\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    ## Zero-pad sequence lenght\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Intents(train_dataset)\n",
    "testing_set = Intents(test_dataset)\n",
    "# Parameters\n",
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'drop_last': False,\n",
    "          'num_workers': 1}\n",
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Forward Pass\n",
    "inp = training_set.__getitem__(0)[0].cuda()\n",
    "output = model(inp)[0]\n",
    "torch.max(output.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 3\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sent = sent.squeeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "          sent = sent.cuda()\n",
    "          label = label.cuda()\n",
    "        output = model.forward(sent)[0]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in testing_loader:\n",
    "                sent = sent.squeeze(0)\n",
    "                if torch.cuda.is_available():\n",
    "                  sent = sent.cuda()\n",
    "                  label = label.cuda()\n",
    "                output = model.forward(sent)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
