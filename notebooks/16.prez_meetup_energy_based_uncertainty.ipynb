{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "## Videos\n",
    "1. ~~[Energy-based Approaches to Representation Learning - Yann LeCun](https://www.youtube.com/watch?v=m17B-cXcZFI)~~\n",
    "2. [Week 7 â€“ Lecture: Energy based models and self-supervised learning](https://www.youtube.com/watch?v=tVwV14YkbYs&feature=youtu.be)  \n",
    "3. [Beyond temperature scaling: Obtaining well-calibrated multiclass probabilities with Dirichlet calibration](https://dirichletcal.github.io/documents/neurips2019/video/Meelis_Ettekanne.mp4) - **Bons slides!**\n",
    "    \n",
    "## Papers\n",
    "\n",
    "### Calibration\n",
    "1. **2005** - [Predicting Good Probabilities With Supervised Learning](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf)\n",
    "2. **2017** - [A baseline for detecting misclassified and out-of-distribution examples in neural networks](https://arxiv.org/pdf/1610.02136.pdf)\n",
    "3. **2017** - [On Calibration of Modern Neural Networks](https://geoffpleiss.com/nn_calibration)  \n",
    "4. **2019** - [Why ReLU networks yield high-confidence predictions far away from\n",
    "the training data and how to mitigate the problem](https://arxiv.org/abs/1812.05720)\n",
    "5. **2019** - [Beyond temperature scaling: Obtaining well-calibrated multiclass probabilities with Dirichlet calibration](https://arxiv.org/pdf/1910.12656.pdf) [2](https://dirichletcal.github.io/)  \n",
    "6. **2020** - [Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks](https://arxiv.org/pdf/2002.10118.pdf)\n",
    "7. **2020** - [Calibrate and Prune: Improving Reliability of Lottery Tickets Through Prediction Calibration](https://arxiv.org/pdf/2002.03875v3.pdf)  \n",
    "8. **2020** - [Unlabelled Data Improves Bayesian Uncertainty Calibration under Covariate Shift](https://arxiv.org/pdf/2006.14988.pdf)  \n",
    "9. **2020** - [Mix-n-Match : Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning](https://arxiv.org/abs/2003.07329)  \n",
    "10. **2021** - [Uncertainty calibration error: a new metric for multi-class classification](https://openreview.net/pdf?id=XOuAOv_-5Fx) \n",
    "\n",
    "\n",
    "### OOD\n",
    "1. [Energy-based Out-of-distribution Detection](https://arxiv.org/abs/2010.03759)\n",
    "2. [A Tutorial on Energy-Based Learning](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf)  \n",
    "3. [Beyond temperature scaling: Obtaining well-calibrated multiclass probabilities with Dirichlet calibration](https://dirichletcal.github.io/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper - [Predicting Good Probabilities](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper - [ReLU high-confidence](https://arxiv.org/pdf/1812.05720.pdf)\n",
    "- ReLu - product almost always high confidence away from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review - [Video Yan Lecun](https://www.youtube.com/watch?v=m17B-cXcZFI&t=75s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reduce amount of supervision, obtain uncertainty info\n",
    "- Not probabilistic view, no need to normalize\n",
    "- Babies learn from observation, with little interaction\n",
    "- Self-supervised learning $\\rightarrow$ next revolution $\\rightarrow$ use parts of the input to learn, without supervision **_\"filling the blanks\"_**\n",
    "- Big question $\\rightarrow$ how to do predictions in presence of uncertainty\n",
    "- Energy-Based Unsupervised Learning\n",
    "     - Learn an energy function F(Y) \n",
    "         - low values on data manifold (iid)\n",
    "         - higher values everywhere else (OOD)\n",
    "     - Unconditional F(y) and Conditional F(x,y)\n",
    "     - Similar to Auto-encoders (Reconstruction error = Energy Function)\n",
    "     - Most intersting strategy to shape energy function F(y), i.e., push OOD points up $\\rightarrow$ **Regularized Latent Variable EBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review [EBM OOD Paper](https://arxiv.org/abs/2010.03759) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review [A Tutorial on Energy-Based Learning](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "bayesian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
